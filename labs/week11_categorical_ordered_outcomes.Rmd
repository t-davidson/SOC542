---
title: "Week 11 - Categorical and Ordered Outcomes"
author: "Fred Traylor, Lab TA"
date: "4/11/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 10)

library(tidyverse)
library(stargazer)
library(naniar)

library(rstanarm)
library(tidybayes)

# library(MASS) # For Ordinal Models
library(nnet) # For Multinomial Models

# Making sure we have the most recent version 
if((packageVersion("modelsummary") != '0.10.0')) 
  remotes::install_github("vincentarelbundock/modelsummary")
library(modelsummary)

library(broom.mixed)
  options(modelsummary_get = "broom")
 
# Making sure we have the most recent version 
if((packageVersion("marginaleffects") != '0.4.1')) 
  remotes::install_github("vincentarelbundock/marginaleffects")
library(marginaleffects)

seed <- 12345
```

We're going to switch it up this week. In March 2020, to mark the 100th Anniversary of the 19th Amendment (which gave (white) women the right to vote in the USA), the Pew Research Center fielded a survey about Americans' perceptions of women's equality. For more on the survey, see the topline report in the lab-data folder or the full report here: https://www.pewresearch.org/social-trends/2020/07/07/a-century-after-women-gained-the-right-to-vote-majority-of-americans-see-work-to-do-on-gender-equality/

"Pew Research Center is a nonpartisan fact tank that informs the public about the issues, attitudes and trends shaping the world. We conduct public opinion polling, demographic research, content analysis and other data-driven social science research. We do not take policy positions." 

All throughout the year, they field surveys on a wide variety of issues, including social and demographic trends, religion, politics, journalism, science, and global affairs. These survey datasets are typically released to the public after an embargo period of one to three years. 

Their survey reports typically only use bivariate analysis, meaning there is a LOT of analysis that is available for secondary researchers. 

This week, we have two research questions: How do members of the public think about the progress in women's rights? And what do they think has been the most important factor in this? We'll be looking at two outcomes:
 - EQRIGHTS2: "When it comes to giving women equal rights with men, do you think our country ... 
      1. has gone too far,
      2. has not gone far enough,
      3. or has been about right?"
      
 - ADVANCE3: "In your opinion, which of the following milestones has been the most important in advancing the position of women in our country? 
      1. Women gaining the right to vote
      2. The availability of the birth control pill
      3. Passage of the Equal Pay Act
      4. Passage of the Family and Medical Leave Act "


# Data Loading and Management

The dataset is in the lab-data folder. Let's load it up and do some data management. 

```{r gss-loading}
pewraw <- haven::read_sav("lab-data/Mar20 19th Amendment_cleaned dataset.sav")

pewamend <- pewraw %>% 
  dplyr::select(
    
    # Target Vars
    EQRIGHTS2, ADVANCE3,
    
    # IV's
    ppage, ppeducat, ppethm, ppgender,
    ppmarit, ppwork, 
    PARTY, IDEO,
    
    weight, 
    
  ) %>% 
  mutate(
    
    # Targets
    rightsprog = ordered(EQRIGHTS2,
                        levels = c(1, 3, 2),
                        labels = c("Too Far", "About Right","Not Far Enough")),
    milestone = factor(ADVANCE3,
                       levels = c(1:4),
                       labels = c("Voting", "BC Pill", "EQ Pay", "Fam Med Leave"))
    ) %>% 
  rename(age = ppage,
         educ = ppeducat,
         race = ppethm,
         gender = ppgender,
         marital = ppmarit,
         employ = ppwork,
         party = PARTY,
         ideo = IDEO) %>% 
  mutate(
    gender = ifelse(gender==1, "Male", "Female"),
    race = case_when(
      race == 1 ~ "White",
      race == 2 ~ "Black", 
      race == 3 ~ "Other", 
      race == 4 ~ "Hispanic",
      race == 5 ~ "Mixed"
      ),
    educ = factor(educ,
                  levels = c(1:4),
                  labels = c("<HS", "High School", "Some College", "College+")),
    marital = case_when(
      marital == 1 ~ "Married",
      marital == 2 ~ "Cohabiting",
      marital == 3 ~ "Divorced",
      marital == 4 ~ "Separated",
      marital == 5 ~ "Widowed",
      marital == 6 ~ "Never Married"
      ),
    employ = case_when(
      employ == 1  ~ "Working",
      employ ==  2 ~ "Self-Employed",
      employ %in% c(3,4) ~ "Unemployed", # Looking for  work or temporary layoff
      employ %in% c(5,6,7) ~ "Not Working"   # Retired, disabled,  other
      ),
    party = case_when(
      party == 1 ~ "Republican",
      party == 2 ~ "Democrat",
      party == 3 ~ "Independent",
      party == 4 ~ "Something Else"
      ),
    ideo = factor(ideo,
                  levels = c(1:5),
                  labels = c("Very Conservative", "Conservative", "Moderate", "Liberal", "Very Liberal"))
  ) %>% 
  dplyr::select(-EQRIGHTS2, -ADVANCE3)
    

```

If you're curious, the code to view the questions and response orders is "lab-data/checking_atp_coding.R". It uses the `foreign::read.spss` function to maintain variable "attributes." This allows for maintaining data information but makes recoding variables slightly harder. Instructions for how to do this are also in the file "lab-data/atp_codebook.pdf".

## Missingness Analysis

Since we're working with new data, let's see if there are any patterns of missingness among the variables. 
```{r miss-upset}
gg_miss_upset(pewamend)
```

Seeing no particular pattern, let's employ listwise deletion. 
```{r list-delete}
pewamend <- pewamend %>% drop_na()
pewamend %>% count
```

## Descriptives
As always, let's look at our descriptive statistics. Since we have only two numeric variables (weight and age), we can simply create a table with means and standard deviations for those, and count and percent for our categorical variables. 
```{r desc-tables, message=FALSE, warning=FALSE}
datasummary_balance( ~ 1,
                     data = pewamend,
                     fmt = 2, # Show 2 decimal places 
                     title = "Sample Descriptive Statistics",
                     notes = "Data: March 2020 Pew Research Center Poll",
                     output = "huxtable")
```

# Ordinal Outcomes: Ordinal Logistic Regression

Our first variable today is whether people think women's rights have gone too far, not far enough, or about right. Because this has an order to it, we call this ordinal. 

### Incorrect: A series of logit or OLS models

A common way of doing this is to create a logit model. Say we're trying to predict just people who say it hasn't gone far enough or just people who say it's gone too far, we could create dummies for these and run a series of logit models. 

Another way of doing this is to create a numeric version of it, such that "not far enough" is 3, "about right" is 2, and "too far" is 1, and then doing an OLS regression 

```{r bad-ordinal}
pewamend <- pewamend %>% 
  fastDummies::dummy_cols("rightsprog") %>% 
  mutate(progress_numeric = case_when(
    rightsprog == "Too Far" ~ 1,
    rightsprog == "About Right" ~ 2,
    rightsprog == "Not Far Enough" ~ 3
  ))

pewamend %>% select(starts_with("rights")) %>% names()
table(pewamend$rightsprog, pewamend$progress_numeric)

rightslog1 <- glm(`rightsprog_Too Far` ~ gender + race + age, data = pewamend, weights = weight, family = "binomial")
rightslog2 <- glm(`rightsprog_About Right` ~ gender + race + age, data = pewamend, weights = weight, family = "binomial")
rightslog3 <- glm(`rightsprog_Not Far Enough` ~ gender + race + age, data = pewamend, weights = weight, family = "binomial")

rightsols <- lm(progress_numeric ~ gender + race + age, data = pewamend, weights = weight)

stargazer(rightslog1, rightslog2, rightslog3, rightsols,  
          omit.stat = c("F", "ser"), single.row = T,
          type = "text")
```

While overall there is a similar pattern among those who've said "not far enough" and our OLS model, the coefficients are different.

More importantly, we're working with an ordinal variable, and we should treat it as such! 

Thinking back to Stats I, we know an ordinal variable is one that has a defined order to it, but there is no similar intervals between the levels. How do we know that the difference between saying "Too Far" and saying "About Right" is the exact same as the difference between saying "About Right" and saying "Not Far Enough?" We don't! 



## Ordinal Logistic Regression
Let's say there's something underlying this: A scale from 0 to 100. We know that the lower values will say "Too Far" and the higher values will say "Not Far Enough," but we don't know where those groups end and the "About Right" group begins. 

This is the value of ordinal logistic regression. Just like binary logistic regression, we're looking for the value(s) that move a person from the base category (Too Far) to the next (About Right), and at the same time, from that category to the next (Not far enough). 

To do this, we use the `MASS::polr()` function. (Yes, the same `MASS` that conflicts with `dplyr`, hence the `package::function()` notation.)

```{r ordinal1}
order1 <- MASS::polr(rightsprog ~ gender + race + age,
                     data = pewamend, weights = weight)
summary(order1)

```

The output looks pretty familiar: a call to say what our formula is, some coefficients and their standard errors. We even get an AIC. 

The bottom part is where things get distinctly ordinal. Remember our jumps from one level to another? This is saying the "intercepts" where those jumps occur. The jump from "Too Far" to "About Right" occurs at -2.9, and the jump from "About Right" to "Not Far Enough" occurs at -0.9. In other programs, you might see this referred to as the "cutpoints." While important to include in the model output, just like other intercepts, we rarely interpret them. 

### Hessian?

You might've noticed we got a message that it was "Re-fitting to get Hessian." Looking at the function documentation (`?polr`), we see that the "Hessian" is akin to an output matrix. Essentially, we should say `Hess = T` if we want to look at the values afterwards. Nothing happens if we don't, but we should include it to quiet the warning. 

```{r hessian}
order1 <- MASS::polr(rightsprog ~ gender + race + age,
                     Hess = T,
                     data = pewamend, weights = weight)
summary(order1)

```


## Interpretation

Let's now add in some variables and see if/how anything changed. Two things about viewing the output:
1. We can't use stargazer.
2. `modelsummary()`'s default methods for displaying significance stars doesn't work with `polr` objects. Instead, we need to run the below command to specify a new method for it that will give us stars. 

```{r ordinal-table}
order2 <- MASS::polr(rightsprog ~ gender + race + age + marital + employ + ideo,
                     Hess = T, data = pewamend, weights = weight)

tidy_custom.polr <- function(x, ...) {
  s <- lmtest::coeftest(x)
  out <- data.frame(
    term = row.names(s),
    p.value = s[, "Pr(>|t|)"])
  out
}

modelsummary(list(order1, order2), output = "huxtable", 
             estimate = "{estimate} ({std.error}) {stars} ", statistic = NULL)

```

So here we see that men have lower log odds of saying there is more progress to be done, as do whites, a finding that holds consistent across both models. In model 2, we see that political ideology increases the log odds of supporting women's progress, and this addition also bolsters the effect of age, such that each additional year of age increases the log odds of supporting progress by .013. 

### Odds Ratios

Lastly, since this functions  as a  GLM, we  can convert log odds (the default output) into odds ratios. (This also takes advantage of  new functionality in `modelsummary()` to include both log odds and odds ratios.)

```{r order-oddsratio}
modelsummary(list("Log Odds" = order2, "Odds Ratio" = order2), output = "huxtable", exponentiate = c(F,T),
             estimate = "{estimate} ({std.error}) {stars} ", statistic = NULL)

```

Above, we see that being male decreases the log odds of favoring continued progress on women's rights, a decrease of about 42% ($1-.578=.422$). Additionally, somebody who is very  liberal is more than 14 times more likely to say progress has not gone far enough ($15.6-1=14.6$).

# Categorical Outcomes: Multinomial Logistic Regression

Our second variable we'll be looking at is which item people think was most important in advancing women's rights. There are four possible responses: Women gaining the right to vote, The availability of the birth control pill, Passage of the Equal Pay Act, and Passage of the Family and Medical Leave Act. 

These were included in the same question, and respondents were asked to pick ONE of these. 

### Incorrect: A series of logit models

One way people will try to analyse these questions is with a series of logistic regression models. Below, I use `fastDummies::dummy_cols()` to create a set of binary indicators for whether a person chose each item. 

I then create a series of logit models to analyze the probability of a person picking this based on their gender, race, and age. 
```{r bad-multi}
pewamend <- pewamend %>% 
  fastDummies::dummy_cols("milestone")
pewamend %>% select(starts_with("miles")) %>% names()

milelog1 <- glm(milestone_Voting ~ gender + race + age, data = pewamend, weights = weight, family = "binomial")
milelog2 <- glm(`milestone_BC Pill` ~ gender + race + age, data = pewamend, weights = weight, family = "binomial")
milelog3 <- glm(`milestone_EQ Pay` ~ gender + race + age, data = pewamend, weights = weight, family = "binomial")
milelog4 <- glm(`milestone_Fam Med Leave` ~ gender + race + age, data = pewamend, weights = weight, family = "binomial")
stargazer(milelog1, milelog2, milelog3, milelog4,
          type = "text")
```

The problem with this is that we are analyzing them separately, but they are all related. 

What we need instead is a model to analyze them TOGETHER. 

## Multinomial Logistic Regression

Enter the multinomial logistic regression model! This allows us to analyze the probability of all choices at once. 

The command is `multinom` from the `nnet` package. Below, I create a multinomial regression model of our milestone dependent variable using gender, race, and age as our independent variables. Just like the `Hess  = T` option from above, we should specify `model = T` so that R maintains information about the model, which  we'll use to calculate $R^2$.

```{r multi1}
mult1 <- multinom(milestone ~ gender + race + age,
                  model = T, data = pewamend, weights = weight)
stargazer(mult1, type = "text", single.row = T,
          notes = "Reference: Women Gaining the Right to Vote")

```

You'll first notice that there are only three columns. This is because it used the first level of the variable (the right to vote) as the reference category. Multinomial regression essentially creates a series of models predicting the likelihood of each of the others, using one reference category for them all. What we get, then, is the likelihood that somebody said the birth control pill, compared to them saying the right to vote; next to it, the likelihood that somebody said equal pay, compared to them saying the right to vote; and lastly, the likelihood they said paid family leave, compared to the right to vote. 

Looking now at our output, we can see a few trends. (NOTE: We interpret this as log odds, just like with logit.) First, let's look at age. Older people were less likly to say the birth control pill was the most significant milestone in advancing women's rights, compared to gaining the right to vote, but were more likely to say paid family and medical leave, also compared to the right to vote. We can do this also with race, where we see whites were less likely to say that either the Equal Pay or Family and Medical Leave Acts were the most important, compared to women's suffrage. 

Additionally, we can see that men were less likely to say all three options were the most importnat, signifying that men are more likely to think the right to vote was the most important.

Let's now see how this compares with one of our outputs from above. 
```{r multi-logit}
stargazer(mult1, milelog4,
          type = "text", single.row = T,
          notes = "Reference: Women Gaining the Right to Vote")
```

The right two columns are where we should direct our interest, since they are the same item. Most notably, we see a drop in significance in the logistic model for men thinking paid family leave was the most important. This is because, the logistic model is comparing men selecting this option compared to all three other ones. 

Now, let's add in some more variables and see how things change. We can hypothesize that married people would find FMLA more important and employed people would find equal pay more important. 

```{r multi2}
mult2 <- multinom(milestone ~ gender + race + age + marital + employ + ideo, 
                  model = T, data = pewamend, weights = weight)

stargazer(mult1, mult2,
          type = "text", report = "vc*", single.row = T, star.cutoffs = c(.05, .01, .001),
          notes = "Reference: Women Gaining the Right to Vote")

```

Well, it turns out marital status didn't have much of an effect here. And employment didn't work as expected, but we do see that unemployed people are less likely to find the FMLA to be most important. Interesting too, liberalism is associated with increased odds of thinking the birth control pill is most important and decreased odds of saying equal pay was most important. 

We also see that the AIC declined in the second model, but only by a little bit, suggesting our additional variables weren't that impactful. 

## Viewing Multinomial Models in Modelsummary

We saw above that multinomial models behave as several models together. This causes a problem for something like `modelsummary()`, but not something unsurmountable. 

```{r mult-ms1}
modelsummary(list(mult1, mult2), stars = T)
```

What happens is that the function doesn't know how we want our table formatted. This is where that `group = ` thing I talked about two weeks ago comes in. We have three items to play with here:
  1. model: the actual thing we put into `modelsummary`. In this case, `mult1`. 
  2. term: our independent variables.
  3. y.level: the specific dependent variable. 

These three items help construct the "grid" of coefficients and standard errors. Below, I use a format that creates a table like stargazer. 

```{r mult-ms2}
modelsummary(mult1, stars = T,
             group = model + term ~ y.level,
             output = "huxtable")
```

This seems like it would be the obvious way to do it. But what about adding a second model? Do we want that below the first? To the right of it? Interspersing the columns? It's all about how you want to display your data and the effects of additional variables. 

Here are four more ways to do this. 

```{r mult-ms3}
# Very long table: good at comparing changes by outcome, but bad at showing comparisons across outcome levels
modelsummary(list(mult1, mult2), stars = T,
             group = y.level + term ~ model,
             output = "flextable"
             )
# Model 2 below Model 1: good for when model2 uses different variable and side-by-side comparison isn't needed
modelsummary(list(mult1, mult2), stars = T,
             group = model + term ~ y.level,
             output = "flextable"
             )
# Model 2 next to Model 1: All around good, but requires going back and forth to compare M1's BC coefficient with M2's
  # This is how stargazer handles multiple models
modelsummary(list(mult1, mult2), stars = T,
             group = term ~ model + y.level,
             output = "flextable"
             )
# Similar to above, but columns are interspersed: Good at showing change in outcome with new variables, but hard to compare within same model
modelsummary(list(mult1, mult2), stars = T,
             group = term ~ y.level + model,
             output = "flextable"
             )
```

There is no right way to  display your outputs, so feel free to play around with these permutations (and others) when  making an output table. 


## Model Diagnostics

Lastly, we can find a pseudo-$R^2$ for our model using the `DescTools::PseudoR2()` function. 

```{r mult-rsquare}
DescTools::PseudoR2(mult1)
DescTools::PseudoR2(mult2)
```


# Baysian Modeling

## Ordinal Models with `stan_polr()`

We can use `rstanarm::stan_polr()` to create Bayesian ordinal models. The big change here is that we have to specify a prior for the $r^2$. 

TOM: Is this true? Any advice on choosing the R2 prior?

```{r bordinal-create}
bordinal1 <- stan_polr(rightsprog ~ gender + race + age + employ,
                      data = pewamend,
                      method = "logistic",
                      prior = R2(location = .15),
                      seed = seed, chains = 1, refresh = 0, 
                      iter = 2000, warmup = 1000)
bordinal2 <- stan_polr(rightsprog ~ gender + race + age + marital + ideo,
                      data = pewamend,
                      method = "logistic",
                      prior = R2(location = .15),
                      seed = seed, chains = 1, refresh = 0, 
                      iter = 2000, warmup = 1000)
print(bordinal2)
prior_summary(bordinal2)
```

We can then use `modelsummary()` just like normal to display our output. (We first have to remove the function we made earlier since our bayesian object is also type "polr.")
```{r bordinal-table}
class(bordinal1)
rm("tidy_custom.polr")
modelsummary(list(bordinal1, bordinal2),
             output = "huxtable")
```

We can also use our regular `rstanarm::loo` and `rstanarm::loo_compare` to create model diagnostics. 
```{r bordinal-loo}
plot(loo_ord1 <- loo(bordinal1))
plot(loo_ord2 <- loo(bordinal2))
loo_compare(loo_ord1, loo_ord2)
```

So here we see that the second model performs much better than the first. 

## Multinomial Models with `brms::`

`rstanarm` doesn't (yet!) have a method to create multinomial models, however. We can use "the other" Bayesian package, BRMS, to do this. 

TOM: Any way to speed this up?

```{r bmult}
bmultstart <- Sys.time()
library(brms)
bmult1 <- brms::brm(milestone ~ gender + race + age,
                    data = pewamend, 
                    # weights = weight,
                    family = categorical(link = "logit"),
                    seed = seed, chains = 1, refresh = 0, 
                    iter = 2000, warmup = 1000)
bmultend <- Sys.time()

```

Let's view it now.
TOM: Advice on making this actually readable? 

```{r bmult-view}
bmultend - bmultstart
print(bmult1)
```


