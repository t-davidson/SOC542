---
title: "Week 10 - Count Outcomes"
author: "Fred Traylor, Lab TA"
date: "4/3/2023"
output: 
  pdf_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 10)

library(tidyverse)
theme_set(theme_light())
library(rstanarm)
library(modelsummary)
library(broom.mixed)
options(modelsummary_get = "broom") 
library(naniar)
library(marginaleffects)

#library(MASS) # For Negative Binomial Models
library(pscl) # For Zero-Inflated Models

seed <- 37827
```


\newpage 

# Data Loading and Management

This week, we'll be looking at three specific variables related to family life: The number of sexual partners, siblings, and children a person has. Since all three are count variables, we'll be using new methods to analyze them. 

```{r gss-loading}
gss2018 <- readRDS("lab_data/GSS2018.Rds") 

gss <- gss2018 %>% 
  dplyr::select(

    # Targets: Partners, Children, and Siblings
    partners, # https://gssdataexplorer.norc.org/variables/5049/vshow
    sibs,     # https://gssdataexplorer.norc.org/variables/51/vshow
    childs,   # https://gssdataexplorer.norc.org/variables/52/vshow
    
    # Demographics 
    marital, 
    sex, age, educ, 
    wtss 
    ) %>% 
  haven::zap_labels() %>% 
  mutate( 
    
    # New Variables
    marital = factor(marital,
                     levels = c(5, 1:4),
                     labels = c("Never Married", "Married", 
                                "Widowed", "Divorced", "Separated")
                     ),

    # Variables we've used before
    age = case_when(
      age > 88 ~ NaN,
      TRUE ~ age
      ),
    sex = factor(sex,
                 levels = c(1,2),
                 labels = c("Male", "Female")
                 ),
    weight = wtss
    ) %>% 
  dplyr::select(-wtss) %>% 
  drop_na()

```

*Note: The `MASS` function, which we will use below, has a function called `select` that conflicts with the `select` used above. For this reason, we will specify the package when calling functions from MASS below*

## Descriptives
As always, let's look at our descriptive statistics. 
```{r desc-tables}
datasummary_skim(gss,
                 type = "numeric",
                 fmt = 2, # Show 2 decimal places 
                 histogram = F,
                 title = "Sample Descriptive Statistics: Continuous Variables",
                 notes = "Data: 2018 General Social Survey",
                 output = "huxtable")

datasummary_skim(gss, 
                 type = "categorical",
                 title = "Sample Descriptive Statistics: Categorical Variables",
                 notes = "Data: 2018 General Social Survey",
                 output = "huxtable")
```

Let's look at our three variables. 
```{r var-plots}
ggpubr::ggarrange(nrow = 3,
                   
  ggplot(gss, aes(partners)) + geom_histogram(binwidth = .5) +
    scale_x_continuous(breaks = seq(0,10)),
  
  ggplot(gss, aes(childs)) + geom_histogram(binwidth = .5) +
    scale_x_continuous(breaks = seq(0,10)),
  
  ggplot(gss, aes(sibs)) + geom_histogram(binwidth = .5)
  
)

```

\newpage 

# OLS Methods 

Let's start by creating three models of our target data using OLS.

```{r ols-mods}
partner_ols <- lm(partners ~ marital + educ + sex + age + I(age^2),
                  data = gss, weights = weight)
sibs_ols <-    lm(sibs ~     marital + educ + sex + age,
                  data = gss, weights = weight)
child_ols <-   lm(childs ~   marital + educ + sex + age,
                  data = gss, weights = weight)

modelsummary(list("Partners" = partner_ols, "Siblings" = sibs_ols, "Children" = child_ols),
             estimate = "{estimate} ({std.error}) {stars}",
             statistic = NULL, gof_omit = "F|IC|RMSE")
```

We see, generally, that widows, women, those who are separated, and those who are older tend to have fewer sexual partners, while those with more education tend to have more. 

Also, those who are separated tend to have more siblings, for some reason, as do women and those who are older. Those with more education tend to have fewer. 

Finally, we see that that people who are (or were) in some sort of marital relationship have more children, which is to be expected. Those who are older also have more children and those who have more education have fewer. 

# Poisson Regression: Number of Partners

In this example, we'll model the number of sexual partners a person has using Poisson regression, which is more suitable for count outcomes.

It takes the same form as our previous GLMs, but setting the family argument to "poisson" instead of "binomial."

For help on creating the model in R, I suggest UCLA's OARC page: https://stats.oarc.ucla.edu/r/dae/poisson-regression/

Their page on interpreting the models is great as well (But the output is in STATA): https://stats.oarc.ucla.edu/stata/output/poisson-regression/

```{r poission}
partner_poi <- glm(partners ~ marital + educ + sex + age + I(age^2),
                   data = gss, weights = weight, family = "poisson")

summary(partner_poi)
```

## Model Output Interpretation

Let's analyze the model.

1. First, note the formmat of the formula used above.

2. Deviance Residuals: We're looking for residuals that are not very skewed. In this case, the median is close to zero, which is good, and the 1st and 3rd quartiles are even enough. Looking at a density plot of the residuals below, we see they're slightly skewed with a tail to the right. Compared to the OLS version, though, it is much more centered. 

```{r poisson-resid}
ggpubr::ggarrange(nrow = 2,
                  
  ggplot(gss, aes(x =  resid(partner_poi))) +
    geom_density(linewidth = 2) + geom_vline(aes(xintercept = 0)),
  
  ggplot(gss, aes( x = resid(partner_ols))) +
    geom_density(linewidth = 2) + geom_vline(aes(xintercept = 0))
  
)
```

3. Coefficients: We interpret these (kind of) like we usually do. A one-year increase in age, for example, is associated with a .015 decrease in the **expected log count** of partners.  

4. Deviance information: We can use this to perform goodness-of-fit tests for the model. Below, I run a chi-squared test, with the null hypothesis that the deviance is acceptable for the number of data points and predictors. We fail to reject the null, so the model is adequately fit. 

```{r poisson-dev}
with(partner_poi, cbind(res.deviance = deviance, 
                        df = df.residual,
                        p = pchisq(deviance, df.residual, lower.tail=FALSE)))
```

## Model Interpretation


```{r poisson-starg}
modelsummary(list("Poisson" = partner_poi, "OLS" = partner_ols), 
             estimate = "{estimate} ({std.error}) {stars}",
             statistic = NULL, gof_omit = "F|IC|RMSE")
```

In interpreting Poisson models, $$ \beta = log(\mu_{x+1}) - log(\mu_x)$$ where going from `x` to `x+1` is the change in `x`. For this reason, we say there is a "difference in the log of expected counts" as we increase `x` by one unit. 

Each additional year of education increases the number of sexual partners a person had in the past year. The difference in the log of expected counts is expected to increase by .016 for each year of education. 

The interpretation goes similarly for contrasts in categorical variables. Somebody who is widowed is expected to have a decrease in the log of the expected counts by .89, and women are expected to have a decrease in the log of the expected counts by .26. 

### Incidence Rate Ratios

We can create incidence rate ratios by exponentiating the coefficients. These can be interpreted similarly to odds ratios. 

When subtracting logs, we can do some algebra to change the form: $$ \beta = log(\mu_{x+1}) - log(\mu_x) = log(\frac{\mu_{x+1}}{\mu_x})$$. 

In other words, we're examining the ratios of the rate of increasing sexual partners by moving from `x` to `x+1`. When we exponentiate this, we go from $$\beta = log(\frac{\mu_{x+1}}{\mu_x}) \rightarrow log(\beta) = \frac{\mu_{x+1}}{\mu_x}$$

As such, we can now talk about changes in the "rate ratio" as we move from `x` to `x+1`. 

```{r poisson-irr}
cbind(Estimate = coef(partner_poi), 
      IRR = exp(coef(partner_poi)),
      exp(confint(partner_poi)))
```

Each year of education increases the incidence rate ratio of sexual partners by a factor of 1.015, or a 1.5% increase, and each year of age (ignoring the square term for now) decreases it by a factor of .027, or a 2.7% increase ($1.027-1 = .027$). 

The interpretation when we talk about categorical contrasts is more straightforward because the change from `x` to `x+1` only occurs once. So females are expected to have a rate of sexual partners that is 22% less than males ($1-.77=.23$). Additionally, widows are expected to have a rate of sexual partners that is 59% lower ($1 - .41=.59$) than never-married individuals. 

*Remember that the IRRs are ratios of one category's rate (e.g. female, widows) to the reference group's rate (e.g. male, never-married).*


## Predictions

We can use our functions from the `marginaleffects` package to create and plot predicted values. 
```{r poisson-pred}
predictions(partner_poi, 
            newdata = datagrid(marital = levels(gss$marital),
                               educ = c(12,18))) %>% 
  as.data.frame() %>% 
  select(marital, educ, estimate, conf.low, conf.high) 
```

We have a table with 10 predictions (5 levels of marital * 2 levels of educ) for the number of sex partners. 

```{r poisson-pred-plot, warning=FALSE}
ggpubr::ggarrange(nrow = 1, common.legend = T, legend = "bottom",
                   
  plot_predictions(partner_poi, condition = c("age", "sex")) +
    ggtitle("Poisson Predicted") + 
    lims(y = c(-.5,2)),
    
  ggplot() + ggtitle("Actual Number") + 
    geom_smooth(gss, mapping = aes(x = age, y = partners, color = sex, fill = sex), alpha = .25) + 
    lims(y = c(-.5,2))

)
```

The model did a pretty good job at predicting partners, although there is substantial sex-based variation in later years that is not captured by the model.

\newpage 

# Negative Binomial: Number of Siblings

## Overdispersion
Overdispersion occurs when the variance is higher than expected under a Poisson distribution. The siblings data are more variable. While most people only have a few siblings, there are several who have more than ten. 

```{r sibs-overdisp}
ggplot(gss, aes(x = sibs)) + geom_histogram(bins = max(gss$sibs))
table(gss$sibs)
```

As a rule of thumb, the residual deviance in a Poisson model should be about equal to the degrees of freedom of the residuals in the model. ([See top of page 4 here.](https://biometry.github.io/APES/LectureNotes/2016-JAGS/Overdispersion/OverdispersionJAGS.pdf)

I create a Poisson model estimating the number of siblings a person has, then divide the null deviance by the degrees of freedom of the residuals. 

```{r sibspoi-dev}
sibs_poisson <- glm(sibs ~ marital + educ + sex + age,
                    data = gss, weights = weight, family = "poisson")
with(sibs_poisson, cbind("Deviance" = deviance,
                         "DF Resid" = df.residual,
                         "Dev / DF" = deviance / df.residual))
```

For comparison, our model estimating sexual partners had a deviance:DF ratio of 0.74. 

```{r partpoi-dev}
with(partner_poi, cbind("Deviance" = deviance,
                         "DF Resid" = df.residual,
                         "Dev / DF" = deviance / df.residual))

```

Since our siblings variable is overdispersed in our currently-specified Poisson model, we will use a negative binomial model. 

It is important to note that overdispersion cannot be diagnosed using summary statistics, although these can be suggestive, but only after attempting to model the data as a Poisson process.

## The Negative Binomial Model

The negative binomial model includes a parameter ($\theta$) that accounts for the overdispersion in the dependent variable. 

The function for negative binomial models comes from the `MASS` package ("Modern Applied Statistics with S"), which was one of the original packages for R and has a ton of statistical tools. It is also the package that overwrites `dplyr::select()`, which is why we use `MASS::glm.nb()` in the code below and `dplyr::select()` in the code at the top. 

To create our negative binomial model, we will use the `MASS::glm.nb()` function. As this function uses a specific distribution we do not need to specify a family like in other GLMs. 

```{r sigs-negbi}
sibs_negbi <- MASS::glm.nb(sibs ~ marital + educ + sex + age,
                           data = gss, weights = weight)

with(sibs_negbi, cbind("Deviance" = deviance,
                       "DF Resid" = df.residual,
                       "Dev / DF" = deviance / df.residual))
```

With this model, we see the deviance:DF ratio is back in order.

Let's take a look at our output.
```{r sibs-negbiout}
summary(sibs_negbi)
```

We see similar output to the Poisson model except for the Theta parameter at the bottom. In this case, lower Theta values indicate more overdispersion. The Negative Binomial distribution converges towards the Poisson distributon as Theta increases.

Note that other software packages including Stata, SAS, and SPSS use an alternative parameterization, where alpha is defined as the inverse of Theta. Higher values of alpha indicate more overdispersion.

## Interpretation

With the modeling done, we can interpret negative binomial coefficients just like Poisson ones. 

Let's create a table to look at our output. 
```{r}
sibscompare <- list("Negative Binomial" = sibs_negbi,
                    "Poisson" = sibs_poisson,
                    "OLS" = sibs_ols)
modelsummary(sibscompare, output = "huxtable", stars = T,
             title = "Modeling Counts of Siblings",
             add_rows = data.frame("Theta", sibs_negbi$theta, "",""))
```

We interpret this just like we do for Poisson models. Note, however, that I had to add in a row to display the Theta parameter for our NB model.

### Incidence Rate Ratios

Just like with the Poisson model, we can also transform our estimates into incidence rate ratios. They are interpreted the same as the Poisson. 

```{r sibs-irr}
cbind(Estimate = coef(sibs_negbi), 
      IRR = exp(coef(sibs_negbi)),
      exp(confint(sibs_negbi)))
```

So each additional year of age increases the IRR by a factor of 1.005 and each additional year of education decreases it by about 6%. Additionally, women tend to have an IRR that is about 10% higher than mens. 

\newpage 

# Zero-Inflation: Number of Children 

Finally, let's consider an example where there may be different processes generating zeros and counts.

```{r}
ggplot(gss, aes(childs)) + geom_histogram(bins = max(gss$childs)) 
table(gss$childs) %>% prop.table() %>% round(3)
```

We see that about 30% of our sample has no children. Looking at the histogram, it looks like there's even the possibility that we have two different distributions:

1. People without children
2. People with children: A Poisson distribution centered around 2 

The Poisson distribution cannot accurately handle this alone.

What we can do instead is use a Zero-Inflated Model. This model has two steps:

1. Model the likelihood of being zero.
2. For nonzero observations, model the counts. 

## Model Creation 
Unfortunately this model is not supported by the standard `glm` function due to some of the additional complexity involved.

To create one, we use the function `pscl::zeroinfl()`, where PSCL stands for "Political Science Computational Laboratory" at Stanford.

In listing the regressors, we put a vertical line (found above enter on the keyboard) to separate the regressors for the count outcome (left side) from those for the zero-inflation outcome (right side). In the model below, I use marital status, age, the number of siblings, and sex for the count model, but marital, age, and education for the zero model.

You can also list one group of regressors that will be used for both parts of the model.

After the term specification, it is optional, but recommended, to specify the distribution for the count model. The default is `dist = "poisson"`, which uses a Poisson distribution. If you think the model would be better fit by a zero-inflated negative binomial model, you can change the distribution to `negbin`. We'll experiment with both.

The default for the zero-inflation model is "logit," specified as `link = "logit"`. Other options (including probit) are available but less frequently used. 


```{r zipmods}
child_zip <-  zeroinfl(childs ~ marital + age + sex + sibs | marital + age + educ,
                       dist = "poisson",
                       data = gss, weights = weight)
child_zinb <- zeroinfl(childs ~ marital + age + sex + sibs | marital + age + educ,
                       dist = "negbin",
                       data = gss, weights = weight)
```

We can then look at the log-likelihood for the two models and compare to see which we want. The function `lmtest::lrtest()` performs a likelihood ratio test to compare the log-likelihoods of the models and quantify the difference with a chi-square. 

```{r zip-loglik}
child_zip$loglik
child_zinb$loglik

lmtest::lrtest(child_zip, child_zinb)
```

In this case, the log-likelihood is the same, so there's no need to use the more complicated negative binomial model. 

## Model Interpretation 

Let's look at the zero-inflated Poisson model more carefully.

```{r child-zip}
summary(child_zip)
```

We can see we have two sections. The top section is the model for counts. Notice how any relationship status increases the predicted number of children compared to those who were never married. Being older and having more siblings are also strongly associated with increasing the number of children. The difference in the log of the expected counts of children decreases by about .04 for each sibling a person has. People from larger families tend to have larger families themselves.

Below the count model, we see the zero-inflation model. Here, we are modeling the likelihood that `childs==0`. This is analogous to a logistic regression predicting whether someone has children using a binary outcome.

As we would expect, being married decreases the likelihood of not having children, as does being older, while education increases it. 


## Viewing ZIM
The way that `modelsummary` extracts coefficients tags each of the terms separately for the zero-inflated and count portions of the model.  Unfortunately this makes it a little tricky to compare with other models as you can see below.

```{r}
modelsummary(list("ZIP" = child_zip, "OLS" = child_ols), 
             output = "huxtable", stars = T)
```

To make the coefficients easier to compare, we can use the `coef_map` option in `modelsummary::modelsummary()` to rename the coefficients. In this case, the count and OLS coefficients are given common names to make those parts comparable.

```{r}

zipnames <- c(
  'count_(Intercept)' = "Constant",
  'count_maritalMarried' = "Married",
  'count_maritalWidowed' = "Widowed",
  'count_maritalDivorced' = "Divorced",
  'count_maritalSeparated' = "Separated",
  'count_age'  = "Age",
  'count_sexFemale' = "Female",
  'count_sibs' = "Siblings",
  '(Intercept)' = "Constant",
  'maritalMarried' = "Married",
  'maritalWidowed' = "Widowed",
  'maritalDivorced' = "Divorced",
  'maritalSeparated' = "Separated",
  'age'  = "Age",
  'sexFemale' = "Female",
  'sibs' = "Siblings",
  'zero_(Intercept)' = "Zero: Constant",
  'zero_maritalMarried' = "Zero: Married",
  'zero_maritalWidowed' = "Zero: Widowed",
  'zero_maritalDivorced' = "Zero: Divorced",
  'zero_maritalSeparated' = "Zero: Separated",
  'zero_age' = "Zero: Age",
  'zero_sexFemale' = "Zero: Female",
  'zero_sibs' = "Zero: Siblings",
  'zero_educ' = "Zero: Education"
)
modelsummary(list("ZI Poisson" = child_zip, 
                  "ZI Neg Bi" = child_zinb,
                  "OLS" = child_ols), 
             coef_map = zipnames,
             output = "huxtable", stars = T)
```

## Predictions

We can create predictions from our estimates using the `marginaleffects` package. 

Below, we see that there seems to be an effect of education and age together, up to around the mid-30's, such that higher levels of education are associated with decreased odds of having children. 

```{r child-pred-educ}
plot_predictions(child_zip, condition = c("age", "educ"))  +
  labs(title = "Predicted Number of Children",
       caption = "Data: 2018 General Social Survey",
       color = "Years of Education",
       fill = "Years of Education",
       y = "Children", x = "Age") +
  theme(legend.position = "bottom")
```

Because I only included education in the zero-inflated portion of the model, we see a logistic curve for those with education and a more linear function for those without. 

But note: This is due to the model formulation. We estimated that education, marital status, and age would have effects on *whether* a person has children, but education is not included in the Poisson model for the *number* of children, hence why there is no education difference in the number. 

We can do this, too, with the number of siblings a person has:

```{r child-pred-sibs}
plot_predictions(child_zip, condition = c("age", "sibs"))  +
  labs(title = "Predicted Number of Children",
       caption = "Data: 2018 General Social Survey",
       color = "Number of Siblings", fill = "Number of Siblings",
       y = "Children", x = "Age") + 
  theme(legend.position = "bottom")
```

In this graph, people with a lot of siblings will have more children, but everyone else is around the same number, though with a slightly increasing trend as people age. 

# Bayesian Models

For Bayesian modeling, as usual, the `stan_glm()` command works out similar to the usual `glm()`. For Poisson models, the `family = "poisson"` argument is also the same. Two quick differences:

1. The big difference is that negative binomial models take the form `family = "neg_binomial_2"` instead of using `glm.nb()` as we did earlier. 
2. There is not (yet!) a method for zero-inflated models in `rstanarm`. As such, we'll be using just the count model (Poisson). 

If you want to know more, you can follow this link to Aki Vehtari's page, where he shows how to do this modeling: https://avehtari.github.io/modelselection/roaches.html

```{r bayesmods}
partner_stan_poisson <- stan_glm(partners ~ marital + educ + sex + age + I(age^2),
                                 data = gss, family = "poisson",
                                 seed = seed, chains = 1, refresh = 0)
sibs_stan_negbi <-      stan_glm(sibs ~ marital + educ + sex + age,
                                 data = gss, family = "neg_binomial_2",
                                 seed = seed, chains = 1, refresh = 0)
child_stan_poisson <-   stan_glm(childs ~ marital + educ + sex + age,
                                 data = gss, family = "poisson",
                                 seed = seed, chains = 1, refresh = 0)

modelsummary(list("Partners" = partner_stan_poisson, 
                  "Siblings" = sibs_stan_negbi, 
                  "Children" = child_stan_poisson),
             output = "huxtable", statistic = "conf.int")

```

Since count data is subject to often-unusual distributions, let's plot our posterior distributions and compare them to the original data. 

```{r bayes-plots}
pp_check(partner_stan_poisson) + ggtitle("Partners, Poisson") + scale_x_continuous(breaks = seq(0,10))
pp_check(sibs_stan_negbi) + ggtitle("Siblings, Neg Binom")
pp_check(child_stan_poisson) + ggtitle("Children, Poisson") + scale_x_continuous(breaks = seq(0,10))
```

As we can see, our model performed exceptionally well on predicting siblings with the negative binomial distribution. For partners, it tended to predict more heavily on 1 than the actual distribution. For children, it actually did fairly well, except for missing the mark on those with only one child. I expect that this is due to the zero-inflated nature of the data, which is not accounted for well in the Poisson model. 


