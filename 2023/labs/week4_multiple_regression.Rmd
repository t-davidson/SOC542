---
title: "Week 4 - Multiple Regression"
author: "Fred Traylor, Lab TA"
date: "2/13/2023"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# options(scipen = 999)

library(tidyverse)
library(rstanarm)
library(tidybayes)
library(latex2exp)

library(modelsummary)
library(broom.mixed)
options(modelsummary_get = "broom") 
library(flextable)

library(usdata)

seed <- 08901
```

# Data

We know that The United States of America has 50 states, but did you know that within those states are 3,142 counties? Because there are so many of them, and their jurisdictions are so small, counties provide great ways to measure social indicators on a local scale.

For today's lab, we're going to use county-level data from the American Community Survey, a nationally-representative survey of Americans. Our data come pre-aggregated at the county-level courtesy of the `usdata` package (install it if needed). For more information about the dataset, use the `?county_2019` command in the console.

Today, we're going to be seeing which variables are associated with the median income of a county. Specifically, we'll be using the percent of residents who are white, the percent of households with a computer, and the percent of adults over age 25 with a high school degree. Let's select just our four variables of interest and shorten household income to be in thousands of dollars to aid in interpretation. We can also use the `datasummary_skim()` function to print summary statistics for our data.

```{r data-table}
counties <- usdata::county_2019 %>% 
  mutate(hhinc_med_thou = median_household_income / 1000) %>% 
  rename(hh_comp = household_has_computer,
         perc_white = white) %>% 
  select(hhinc_med_thou, perc_white, hs_grad, hh_comp) 

datasummary_skim(counties, title = "County Summary Statistics",
                 notes = "Data: 2019 American Communities Survey")
```

To get a look at what our data looks like, let's make a series of scatterplots such that each of our independent variables has it's own graph with the dependent variable. We can also use the `geom_smooth()` function to show a bivariate regression line for them.

```{r data-viz}
counties %>% 
  
  # Reshaping data so columns for predictor and predictor value 
  pivot_longer(cols = c(perc_white, hs_grad, hh_comp),
               names_to = "predictor",
               values_to = "pred_value") %>% 
  
  # Plotting
  ggplot(aes(x = pred_value,
             y = hhinc_med_thou)) +
  geom_point(alpha=0.3, shape = 1) +
  geom_smooth(method = "lm", formula = 'y ~ x', se = T) +
  facet_grid(~predictor, scales = "free_x") +
  theme_light() + theme(plot.title = element_text(hjust = .5)) +
  labs(y = "Median Household Income", x = "",
       title = "Bivariate Relationships") 
```

\newpage 

# The Frequentist Approach

For the past two weeks, we looked at creating regression models where one independent variables acted upon one dependent variable. These models looked like: $$y = \alpha + \beta x + \epsilon$$

When we have two (or more) independent variables, we simply "add" them to the model formula. (They are called "additive" models for this reason.) With this, we can go from a *bivariate* model to a *multivariate* one. These equations take the form of: $$y = \alpha + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k + \epsilon$$ for $k$ number of independent variables.

Let's start by modeling the bivariate relationship between median household income and the percentage of each house in the county that has a computer. Then, let's also do the percent of adults over age 25 with a high school diploma and the percent who are white.

Finally, we'll create a multivariate model to see how these relationships change when put together. Notice how, in the additive model, we simply *add* the additional independent variables onto each other: $lm(y \sim x_1 + x_2 + ... + x_k, data = dataset)$ 

```{r freq-model}
ols_bivar_comp <- lm(hhinc_med_thou ~ hh_comp, data = counties)
ols_bivar_educ <- lm(hhinc_med_thou ~ hs_grad, data = counties)
ols_bivar_white <- lm(hhinc_med_thou ~ perc_white, data = counties)

ols_multi <- lm(hhinc_med_thou ~ hh_comp + hs_grad + perc_white, 
                data = counties)
```

## Comparing Frequentist Coefficients

Now that we have them created, we'll throw these into the `modelsummary()` function (from the package of the same name) to compare them side-by-side. Before we do this, though, let's put them all into a `list()`, and rename and order our predictors.

1.  We put the three models into a list just to make it easier to read our final `modelsummary()` function's arguments. This also gives us a chance to assign names to our models that will show up at the top of the regression output table. Similar to `rename()`, this takes the form `"New Name" = "old_name"`.

2.  And then we can create a vector that specifies the names we had in our original models and what we would like them to be called in the output table. (Because it has to be confusing, or it wouldn't be R, this takes the form `"old_name" = "New Name"`.) This also gives us a chance to reorder the coefficients, so I've moved the intercept term to the bottom, where we would normally see it in a regression table in a published article.

3.  In the `modelsummary()` function, we first include the list of our models. We could stop there and be fine. However, let's also make a few customizations: 
    -   Add in our coefficient names into the `coef_map` argument.
    -   Tell it to give us significance stars. 
    -   Omit any "goodness-of-fit" (or "`gof`") statistics aside from the number of observations (for all models) and the $r^2$ and F-statistic.
    -   Give our table a title.

```{r freq-model-comp}
# Renaming the Models (Column Names on Top)
model_list <- list("Computer Ownership" = ols_bivar_comp, 
                   "HS Grad Rate" = ols_bivar_educ,
                   "Percent White" = ols_bivar_white,
                   "Multivariate" = ols_multi)

# Renaming variables (Row names on left)
coef_names <- c("hh_comp" = "Computer Ownership",
                "hs_grad" = "% High School Grad",
                "perc_white" = "% White",
                "(Intercept)" = "Intercept")

modelsummary(model_list, coef_map = coef_names,
             stars = T,
             gof_omit = "IC|Log|alg|RMSE",
             title = "Frequentist Regression Output: County Median HH Income")

```

## Visualizing Frequentist Coefficients

### By Hand

We can also plot these our models using `ggplot2`. First, using the `tidy()` function in the `broom` package, we can quickly turn our three models into data frames. We can then combine them together into one big frame.

```{r freq-viz-table}
ols_sum_comp <- broom::tidy(ols_bivar_comp, conf.int = T) %>% 
  mutate(model = "Computer Only")
ols_sum_educ <- broom::tidy(ols_bivar_educ, conf.int = T) %>% 
  mutate(model = "Education Only")
ols_sum_white <- broom::tidy(ols_bivar_white, conf.int = T) %>% 
  mutate(model = "Race Only ")
ols_sum_multi <- broom::tidy(ols_multi, conf.int = T) %>% 
  mutate(model = "OLS Multivariate")

ols_sum_ints <- bind_rows(ols_sum_comp, ols_sum_educ, 
                          ols_sum_white, ols_sum_multi) %>% 
  filter(term != "(Intercept)")
print(ols_sum_ints) 
```

Looking at the table above, we can see that the `tidy()` function created a row for each variable that lists the estimate, standard error, t-statistic, and p-value. We then told it to give us the confidence interval (defaulting to 95%), and add a column specifying the model name. We then combined the data frames and removed the intercepts.

Now that our models are in a dataframe, we can simply plot them using `ggplot`.

```{r freq-viz}
ggplot() + 
  geom_pointrange(
    data = ols_sum_ints,
    aes(y = model, x = estimate,
        xmin = conf.low, xmax = conf.high)) + 
  geom_vline(data = filter(ols_sum_ints, term !="hh_comp"), 
             # hh_comp's coef is not close to zero, so not including it here
             aes(xintercept = 0), alpha = .5,
                 linetype = "dotted", linewidth = 1.5) +
  facet_grid(~ term, scales = "free") + 
  theme_light() +
  labs(y = "Model", x = "Coefficient Estimate",
       title = "US Counties' Median Household Income (in Thousand USD)",
       caption = "Data: 2019 American Communities Survey") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = .5))
```

### Using `modelplot()`

Alternatively, we can use `modelsummary::modelplot()` to do the same. It performs the same tidying operations as above and presents a ggplot() based output. This means we can then simply add (`+`) any geometries or extras onto it. In this case, I add a vertical line at 0 along with titles and other formatting.

```{r}
modelplot(model_list, # List of models
          coef_omit = "Inter", # Omit the intercept
          coef_rename = coef_names) + # New variable names from above
  
  geom_vline(aes(xintercept = 0),
             linetype = "dashed", linewidth = 1, alpha = .5) +
  theme_light() +
  labs(y = "", x = "Coefficient Estimate", color = "Model",
       title = "Regression Coefficients",
       subtitle = "US Counties' Median Household Income (in Thousand USD)",
       caption = "Data: 2019 American Communities Survey") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = .5), 
        plot.subtitle = element_text(hjust = .5))
  
```

Note, however, that the different coefficient sizes makes it hard to see the values as well. You can imagine what this would do with coefficients that are even further apart.

\newpage 

# The Bayesian Approach

Let's now recreate our multivariate model with a Bayesian approach.

## Flat Priors

Let's first go in without any prior knowledge of the distribution.

```{r bayes-flat-model}
bayes_flat_mod <- stan_glm(hhinc_med_thou ~ perc_white + hs_grad + hh_comp, 
                     data = counties, seed = seed, 
                     prior = NULL, prior_intercept = NULL, prior_aux = NULL,
                     chains = 1, refresh = 0)
print(bayes_flat_mod, digits = 2, detail = T)
prior_summary(bayes_flat_mod)

```

## Specified Priors

Let's also create a model with alternative priors. In this case, we `rstanarm` provides defaults for each prior. To use the defaults, we can just run the model without specifying any priors.

```{r bayes-prior-model}
# Model 
bayes_prior_mod <- stan_glm(hhinc_med_thou ~ perc_white + hs_grad + hh_comp,
                            data = counties, seed = seed,
                            chains = 4, refresh = 0)
print(bayes_prior_mod, digits = 2, detail = T) 
```

We can look at the prior summary to see the defaults used. In this case, we can see that it used normal distributions for the intercept and coefficients, and an exponential prior for sigma.

```{r bayes-prior-sum}
prior_summary(bayes_prior_mod)
```

We can also visualize our model like we did last week. First, we `gather_draws()` and specifying which variables we would like. In this case, we don't want the intercept, so we write everything *but* that.

```{r bayes-gather-draws-prior}
draws_prior <- bayes_prior_mod %>% 
  gather_draws(perc_white, hs_grad, hh_comp) %>% 
  mutate(model = "Bayes Default")
head(draws_prior)
```

We can then send this into `ggplot` to create a graph that shows our estimates and their uncertainty. Note that the three variables get their own graphs, along the lines of what we did at the very beginning with the scatter plot. If you look back at our model output, you'll see that household computer rate's coefficient is much larger than the other two variables. Faceting the variables into their own graphs allows for the variance in each one to be seen.

```{r bayes-viz}
draws_prior %>% 
  ggplot(aes(y = .variable, x = .value)) +
  stat_halfeye() + theme_light() + 
  labs(x = "Coefficient", y = "Variable") +
  facet_grid(~ .variable, 
             scales = "free")
```

## Bayesian R-Squared

Because we estimated 1000 models in each of our Bayes estimates, we also have 1000 $R^2$'s. We can use the `bayes_R2()` function to get the $R^2$ for each model and then plot the densities to find where they end up.

```{r bayes-r2}

bayes_prior_r2 <- bayes_R2(bayes_prior_mod) %>% 
  as.data.frame() %>% mutate(model = "Default Priors")
bayes_flat_r2 <- bayes_R2(bayes_flat_mod) %>% 
  as.data.frame() %>% mutate(model = "Flat Priors")

bayes_rsquared <- rbind(bayes_flat_r2, bayes_prior_r2)
colnames(bayes_rsquared) <- c("rsquared", "model")

# Finding the mean and median r-squared for each model
rsquared_sums <- bayes_rsquared %>% 
  group_by(model) %>% 
  summarize(mean = mean(rsquared),
            median = median(rsquared))

ggplot() +
  stat_halfeye(data = bayes_rsquared,
               mapping = aes(x = rsquared), alpha = .7) + 
  geom_vline(data = rsquared_sums, 
             mapping = aes(xintercept = mean, color = "Mean"), 
             linewidth = 1.25, linetype = "dashed") + 
  geom_vline(data = rsquared_sums,
             mapping = aes(xintercept = mean, color = "Median"), 
             linewidth = 1.25, linetype = "dotted") +
  facet_grid(model ~ .) + theme_light() +
  labs(y = "Density", x =  TeX("$R^2$"), color = "")

```

\newpage 

# Model Comparison

## Model Comparison Table

Finally, let's compare all three of our models we made today. We can use the `modelsummary()` function from earlier to put them all into a table. The results show how the data quickly overwhelmed the prior. In both cases, the Bayesian estimates are almost identical to those from the OLS model.

```{r compare-table, message=FALSE}
model_list <- list("OLS Multivariate" = ols_multi, 
                   "Bayes: Flat Prior" = bayes_flat_mod, 
                   "Bayes: Default Prior" = bayes_prior_mod)

# coef_names <- c("hh_comp" = "% HH's w/Comp.",
#                 "hs_grad" = "% HS Grad",
#                 "perc_white" = "% White",
#                 "(Intercept)" = "Constant")

# Adding in Bayes R2 
# Comment it out if it doesn't work for you
bayesrows <- data.frame(
  
  c("Bayes R2 (Mean)", 
    "Bayes R2 (Median)",
    "Bayes R2 (SD)"),
  
  c("", "",""), # OLS Model Blanks
  
  c(mean(bayes_R2(bayes_flat_mod)),
    median(bayes_R2(bayes_flat_mod)),
    sd(bayes_R2(bayes_flat_mod))),
  
  c(mean(bayes_R2(bayes_prior_mod)),
    median(bayes_R2(bayes_prior_mod)),
    sd(bayes_R2(bayes_prior_mod)))
)


modelsummary(model_list,
             coef_map = coef_names,
             gof_omit = "IC|Log|alg|pss|RMSE|F", 
             add_rows = bayesrows,
             title = "Frequentist vs Bayesian Regression Model Output") 

```

## Model Comparison Graph

As always, we should also plot our coefficients to compare the model outputs. Just like before, we need to `gather_draws()` from the posterior distribution of our flat Bayesian model.

```{r compare-graph}
draws_flat <- bayes_flat_mod %>% 
  gather_draws(perc_white, hs_grad, hh_comp) %>% 
  mutate(model = "Bayes Flat")


all_draws <- bind_rows(draws_flat, draws_prior) %>% 
  rename(estimate = .value, term = .variable)

ggplot() +
  stat_halfeye(
    data = all_draws,
    aes(x = estimate, y = model, 
        fill = model, alpha = .8)) +
  geom_pointrange(
    data = filter(ols_sum_ints, model =="OLS Multivariate"),
    aes(y = model, x = estimate,
        xmin = conf.low, xmax = conf.high,
        fill = model )) + 
  geom_vline(data = filter(all_draws, term =="hs_grad"), 
             # This is just so it only shows on hs_grad 
             aes(xintercept = 0), 
             linetype = "dotted", linewidth = 1.5, alpha = .5) +
  facet_grid(~ term, scales = "free") + 
  theme_light() + scale_fill_viridis_d() + 
  labs(y = "Model", x = "Coefficient Estimate",
       title = "Regression Coefficients: \n US Counties' Median Household Income (in Thousand USD)",
       caption = "Data: 2019 American Communities Survey") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = .5))

```

# Posterior predictive checks

We can also use the Bayesian model to get a sense of how well the model fits the data.
```{r posterior predictive check}
pp_check(bayes_prior_mod)
```